{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f7570d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "728c7763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Khushi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, Khushi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b96d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google API key is set.\n"
     ]
    }
   ],
   "source": [
    "if google_api_key:\n",
    "    print(\"Google API key is set.\")\n",
    "else:  \n",
    "    print(\"Google API key is not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af2d29ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/QASystem/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "import google.generativeai as genai\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import ServiceContext\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49d5b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b6234f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001 PaLM 2 Chat (Legacy) A legacy text-only model optimized for chat conversations\n",
      "models/text-bison-001 PaLM 2 (Legacy) A legacy model that understands text and generates text as an output\n",
      "models/embedding-gecko-001 Embedding Gecko Obtain a distributed representation of a text.\n",
      "models/gemini-1.0-pro-vision-latest Gemini 1.0 Pro Vision The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "models/gemini-pro-vision Gemini 1.0 Pro Vision The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "models/gemini-1.5-pro-latest Gemini 1.5 Pro Latest Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "models/gemini-1.5-pro-001 Gemini 1.5 Pro 001 Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "models/gemini-1.5-pro-002 Gemini 1.5 Pro 002 Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.\n",
      "models/gemini-1.5-pro Gemini 1.5 Pro Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "models/gemini-1.5-flash-latest Gemini 1.5 Flash Latest Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "models/gemini-1.5-flash-001 Gemini 1.5 Flash 001 Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "models/gemini-1.5-flash-001-tuning Gemini 1.5 Flash 001 Tuning Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "models/gemini-1.5-flash Gemini 1.5 Flash Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "models/gemini-1.5-flash-002 Gemini 1.5 Flash 002 Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.\n",
      "models/gemini-1.5-flash-8b Gemini 1.5 Flash-8B Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "models/gemini-1.5-flash-8b-001 Gemini 1.5 Flash-8B 001 Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "models/gemini-1.5-flash-8b-latest Gemini 1.5 Flash-8B Latest Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "models/gemini-1.5-flash-8b-exp-0827 Gemini 1.5 Flash 8B Experimental 0827 Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "models/gemini-1.5-flash-8b-exp-0924 Gemini 1.5 Flash 8B Experimental 0924 Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "models/gemini-2.5-pro-exp-03-25 Gemini 2.5 Pro Experimental 03-25 Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.5-pro-preview-03-25 Gemini 2.5 Pro Preview 03-25 Gemini 2.5 Pro Preview 03-25\n",
      "models/gemini-2.5-flash-preview-04-17 Gemini 2.5 Flash Preview 04-17 Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.0-flash-exp Gemini 2.0 Flash Experimental Gemini 2.0 Flash Experimental\n",
      "models/gemini-2.0-flash Gemini 2.0 Flash Gemini 2.0 Flash\n",
      "models/gemini-2.0-flash-001 Gemini 2.0 Flash 001 Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "models/gemini-2.0-flash-exp-image-generation Gemini 2.0 Flash (Image Generation) Experimental Gemini 2.0 Flash (Image Generation) Experimental\n",
      "models/gemini-2.0-flash-lite-001 Gemini 2.0 Flash-Lite 001 Stable version of Gemini 2.0 Flash Lite\n",
      "models/gemini-2.0-flash-lite Gemini 2.0 Flash-Lite Gemini 2.0 Flash-Lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05 Gemini 2.0 Flash-Lite Preview 02-05 Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "models/gemini-2.0-flash-lite-preview Gemini 2.0 Flash-Lite Preview Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "models/gemini-2.0-pro-exp Gemini 2.0 Pro Experimental Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.0-pro-exp-02-05 Gemini 2.0 Pro Experimental 02-05 Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-exp-1206 Gemini Experimental 1206 Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 Gemini 2.5 Flash Preview 04-17 Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.0-flash-thinking-exp Gemini 2.5 Flash Preview 04-17 Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.0-flash-thinking-exp-1219 Gemini 2.5 Flash Preview 04-17 Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/learnlm-1.5-pro-experimental LearnLM 1.5 Pro Experimental Alias that points to the most recent stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "models/learnlm-2.0-flash-experimental LearnLM 2.0 Flash Experimental LearnLM 2.0 Flash Experimental\n",
      "models/gemma-3-1b-it Gemma 3 1B \n",
      "models/gemma-3-4b-it Gemma 3 4B \n",
      "models/gemma-3-12b-it Gemma 3 12B \n",
      "models/gemma-3-27b-it Gemma 3 27B \n",
      "models/embedding-001 Embedding 001 Obtain a distributed representation of a text.\n",
      "models/text-embedding-004 Text Embedding 004 Obtain a distributed representation of a text.\n",
      "models/gemini-embedding-exp-03-07 Gemini Embedding Experimental 03-07 Obtain a distributed representation of a text.\n",
      "models/gemini-embedding-exp Gemini Embedding Experimental Obtain a distributed representation of a text.\n",
      "models/aqa Model that performs Attributed Question Answering. Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n",
      "models/imagen-3.0-generate-002 Imagen 3.0 002 model Vertex served Imagen 3.0 002 model\n",
      "models/gemini-2.0-flash-live-001 Gemini 2.0 Flash 001 Gemini 2.0 Flash 001\n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    print(model.name, model.display_name, model.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10dd2fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro-vision-latest Gemini 1.0 Pro Vision The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "models/gemini-pro-vision Gemini 1.0 Pro Vision The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.\n",
      "models/gemini-1.5-pro-latest Gemini 1.5 Pro Latest Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "models/gemini-1.5-pro-001 Gemini 1.5 Pro 001 Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "models/gemini-1.5-pro-002 Gemini 1.5 Pro 002 Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.\n",
      "models/gemini-1.5-pro Gemini 1.5 Pro Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.\n",
      "models/gemini-1.5-flash-latest Gemini 1.5 Flash Latest Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "models/gemini-1.5-flash-001 Gemini 1.5 Flash 001 Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "models/gemini-1.5-flash-001-tuning Gemini 1.5 Flash 001 Tuning Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.\n",
      "models/gemini-1.5-flash Gemini 1.5 Flash Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.\n",
      "models/gemini-1.5-flash-002 Gemini 1.5 Flash 002 Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.\n",
      "models/gemini-1.5-flash-8b Gemini 1.5 Flash-8B Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "models/gemini-1.5-flash-8b-001 Gemini 1.5 Flash-8B 001 Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "models/gemini-1.5-flash-8b-latest Gemini 1.5 Flash-8B Latest Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.\n",
      "models/gemini-1.5-flash-8b-exp-0827 Gemini 1.5 Flash 8B Experimental 0827 Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "models/gemini-1.5-flash-8b-exp-0924 Gemini 1.5 Flash 8B Experimental 0924 Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).\n",
      "models/gemini-2.5-pro-exp-03-25 Gemini 2.5 Pro Experimental 03-25 Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.5-pro-preview-03-25 Gemini 2.5 Pro Preview 03-25 Gemini 2.5 Pro Preview 03-25\n",
      "models/gemini-2.5-flash-preview-04-17 Gemini 2.5 Flash Preview 04-17 Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.0-flash-exp Gemini 2.0 Flash Experimental Gemini 2.0 Flash Experimental\n",
      "models/gemini-2.0-flash Gemini 2.0 Flash Gemini 2.0 Flash\n",
      "models/gemini-2.0-flash-001 Gemini 2.0 Flash 001 Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "models/gemini-2.0-flash-exp-image-generation Gemini 2.0 Flash (Image Generation) Experimental Gemini 2.0 Flash (Image Generation) Experimental\n",
      "models/gemini-2.0-flash-lite-001 Gemini 2.0 Flash-Lite 001 Stable version of Gemini 2.0 Flash Lite\n",
      "models/gemini-2.0-flash-lite Gemini 2.0 Flash-Lite Gemini 2.0 Flash-Lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05 Gemini 2.0 Flash-Lite Preview 02-05 Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "models/gemini-2.0-flash-lite-preview Gemini 2.0 Flash-Lite Preview Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite\n",
      "models/gemini-2.0-pro-exp Gemini 2.0 Pro Experimental Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.0-pro-exp-02-05 Gemini 2.0 Pro Experimental 02-05 Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-exp-1206 Gemini Experimental 1206 Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "models/gemini-2.0-flash-thinking-exp-01-21 Gemini 2.5 Flash Preview 04-17 Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.0-flash-thinking-exp Gemini 2.5 Flash Preview 04-17 Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/gemini-2.0-flash-thinking-exp-1219 Gemini 2.5 Flash Preview 04-17 Preview release (April 17th, 2025) of Gemini 2.5 Flash\n",
      "models/learnlm-1.5-pro-experimental LearnLM 1.5 Pro Experimental Alias that points to the most recent stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.\n",
      "models/learnlm-2.0-flash-experimental LearnLM 2.0 Flash Experimental LearnLM 2.0 Flash Experimental\n",
      "models/gemma-3-1b-it Gemma 3 1B \n",
      "models/gemma-3-4b-it Gemma 3 4B \n",
      "models/gemma-3-12b-it Gemma 3 12B \n",
      "models/gemma-3-27b-it Gemma 3 27B \n"
     ]
    }
   ],
   "source": [
    "for model in genai.list_models():\n",
    "    if 'generateContent' in model.supported_generation_methods:\n",
    "        print(model.name, model.display_name, model.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801df2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
